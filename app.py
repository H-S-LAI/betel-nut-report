import streamlit as st
import pandas as pd
import io
import os
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell

# --- 1. æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨èƒ½è®€å–èˆ‡ä¿®å¾© (ç¶­æŒä¸è®Š) ---
def load_and_fix_smart(uploaded_file):
    file_name = uploaded_file.name
    file_ext = os.path.splitext(file_name)[1].lower()
    df = None

    if file_ext in ['.xls', '.xlsx']:
        try:
            if file_ext == '.xls':
                df = pd.read_excel(uploaded_file, engine='xlrd')
            else:
                df = pd.read_excel(uploaded_file, engine='openpyxl')
        except Exception as e:
            return None, f"Excel è®€å–å¤±æ•—: {e}"
    else:
        bytes_data = uploaded_file.getvalue()
        content = ""
        try:
            text_utf8 = bytes_data.decode('utf-8')
            if 'Â©Â±' in text_utf8 or 'Â§O' in text_utf8: 
                content = text_utf8.encode('latin1', errors='ignore').decode('cp950', errors='ignore')
            else:
                content = text_utf8
        except:
            try:
                content = bytes_data.decode('cp950', errors='ignore')
            except:
                content = bytes_data.decode('latin1', errors='ignore')

        lines = content.splitlines()
        header_row_index = -1
        for i, line in enumerate(lines[:20]): 
            if "åº—å" in line and "å”®é‡" in line:
                header_row_index = i
                break
        if header_row_index == -1:
            return None, f"æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—ã€‚"

        try:
            valid_content = "\n".join(lines[header_row_index:])
            df = pd.read_csv(io.StringIO(valid_content))
        except Exception as e:
            return None, f"è§£æž CSV å¤±æ•—: {e}"

    if df is not None:
        try:
            target_df = pd.DataFrame()
            df.columns = [str(c).strip() for c in df.columns]

            if 'åº—å' in df.columns and 'å”®é‡' in df.columns:
                target_df = df
            elif df.shape[1] >= 4:
                target_df = df.iloc[:, [1, 2, 3]].copy()
                target_df.columns = ['åº—å', 'å“å', 'å”®é‡']
            else:
                return None, f"æ¬„ä½è­˜åˆ¥å¤±æ•—ã€‚"

            target_df['å”®é‡'] = pd.to_numeric(target_df['å”®é‡'], errors='coerce').fillna(0)
            target_df = target_df.dropna(subset=['åº—å'])
            target_df = target_df[target_df['åº—å'].astype(str).str.contains("åº—å") == False]
            return target_df, "Success"
        except Exception as e:
            return None, f"è³‡æ–™æ¨™æº–åŒ–å¤±æ•—: {e}"
    return None, "Unknown Error"

# --- åŠŸèƒ½ï¼šå®‰å…¨å¯«å…¥ (è§£æ±º MergedCell éŒ¯èª¤) ---
def safe_write(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        for rng in ws.merged_cells.ranges:
            if cell.coordinate in rng:
                top_left = ws.cell(row=rng.min_row, column=rng.min_col)
                top_left.value = value
                return
    else:
        cell.value = value

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šå¡«å¯« Excel (V11 æ™ºæ…§è·³èºç‰ˆ) ---
def fill_excel_template(template_path_or_file, combined_df, grains_per_pack_map):
    if isinstance(template_path_or_file, str):
        wb = load_workbook(template_path_or_file)
    else:
        wb = load_workbook(template_path_or_file)
    ws = wb.active

    # ==========================================
    # æº–å‚™å·¥ä½œ
    # ==========================================
    global_total_grains_by_product = {} 
    global_total_packs_all = 0
    col_product_map = {}

    # 1. æ•´ç†éŠ·å”®æ•¸æ“š
    data_dict = {}
    for index, row in combined_df.iterrows():
        store = str(row['åº—å']).strip()
        product = str(row['å“å']).strip()
        sales = row['å”®é‡']
        
        if store not in data_dict:
            data_dict[store] = {}
        
        matched_key = product
        for key in grains_per_pack_map.keys():
            if key in product:
                matched_key = key
                break
        data_dict[store][matched_key] = data_dict[store].get(matched_key, 0) + sales

    # å®šä½ Header
    header_row = 3
    for r in range(1, 10):
        val = ws.cell(row=r, column=1).value
        if val and "åº—" in str(val):
            header_row = r
            break
            
    # 2. å¡«å¯«åˆ†åº—æ•¸æ“š
    store_cols = []
    for col in range(1, ws.max_column + 1):
        val = ws.cell(row=header_row, column=col).value
        if val and "åº—" in str(val):
            store_cols.append(col)

    for store_col in store_cols:
        prod_col = store_col + 1
        sales_col = store_col + 2
        
        for r in range(header_row + 1, ws.max_row + 1):
            cell_store = ws.cell(row=r, column=store_col).value
            if not cell_store or "éŠ·å”®" in str(cell_store):
                continue
            
            store_name = str(cell_store).strip()
            cell_prod = ws.cell(row=r, column=prod_col).value
            if not cell_prod:
                continue
            prod_name_in_excel = str(cell_prod).strip()
            
            if store_name in data_dict:
                sales_val = 0
                for key_prod in data_dict[store_name]:
                    if key_prod in prod_name_in_excel or prod_name_in_excel in key_prod:
                        sales_val = data_dict[store_name][key_prod]
                        break
                if sales_val > 0:
                    safe_write(ws, r, sales_col, sales_val)

    # ==========================================
    # 3. è™•ç†ã€Œç´…è‰²åŒ…æ•¸ã€èˆ‡ã€Œè—è‰²ç²’æ•¸ã€
    # ==========================================
    pack_rows = []
    for r in range(1, ws.max_row + 1):
        val = ws.cell(row=r, column=1).value
        if val and "éŠ·å”®åŒ…æ•¸" in str(val):
            pack_rows.append(r)

    for r_pack in pack_rows:
        r_grain = -1
        if ws.cell(row=r_pack + 1, column=1).value and "éŠ·å”®ç²’æ•¸" in str(ws.cell(row=r_pack + 1, column=1).value):
            r_grain = r_pack + 1

        for col in range(1, ws.max_column + 1):
            found_product = None
            for offset in range(1, 6):
                val = ws.cell(row=r_pack - offset, column=col).value
                if val and isinstance(val, str) and len(val) > 1:
                    for key in grains_per_pack_map.keys():
                        if key in val:
                            found_product = key
                            break
                    if found_product:
                        break
            
            if found_product:
                col_product_map[col] = found_product
                col_product_map[col + 1] = found_product

                # æ›´æ–°ç¶ è‰² (ç²’æ•¸è¨­å®š)
                setting_val = grains_per_pack_map.get(found_product)
                safe_write(ws, r_pack, col, setting_val)
                
                # è¨ˆç®—ç´…è‰²
                current_red_sum = 0
                for offset in range(1, 20):
                    r_scan = r_pack - offset
                    if r_scan <= header_row: break
                    val = ws.cell(row=r_scan, column=col + 1).value
                    if isinstance(val, (int, float)):
                        current_red_sum += val
                
                # å¯«å…¥ç´…è‰²
                cell_red = ws.cell(row=r_pack, column=col + 1)
                cell_red_val = 0
                if isinstance(cell_red, MergedCell):
                     cell_red_val = current_red_sum
                else:
                     cell_red_val = cell_red.value
                     if not isinstance(cell_red_val, (int, float)):
                         cell_red_val = current_red_sum
                
                safe_write(ws, r_pack, col + 1, cell_red_val)
                global_total_packs_all += cell_red_val

                # å¯«å…¥è—è‰²
                total_grains = cell_red_val * setting_val
                if r_grain != -1:
                    safe_write(ws, r_grain, col + 1, total_grains)
                
                if found_product not in global_total_grains_by_product:
                    global_total_grains_by_product[found_product] = 0
                global_total_grains_by_product[found_product] += total_grains

    # ==========================================
    # 4. è™•ç†ã€Œç²’æ•¸ç¸½è¨ˆã€åˆ— èˆ‡ ã€Œç¸½ç²’æ•¸ / ç¸½åŒ…æ•¸ã€ (é‡è¦ä¿®æ­£ï¼)
    # ==========================================
    
    row_summary = -1
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 10):
            val = str(ws.cell(row=r, column=c).value).strip()
            if "ç²’æ•¸ç¸½è¨ˆ" in val:
                row_summary = r
                break
        if row_summary != -1: break

    # A. å¡«å¯«ã€Œç²’æ•¸ç¸½è¨ˆã€åˆ—
    exclude_list = ["å¤šè", "æ™®é€š"]
    if row_summary != -1:
        for col in range(1, ws.max_column + 1):
            prod_name = col_product_map.get(col)
            if prod_name:
                if prod_name not in exclude_list:
                    val = global_total_grains_by_product.get(prod_name, 0)
                    safe_write(ws, row_summary, col, val)
                else:
                    safe_write(ws, row_summary, col, "")

    # B. å¡«å¯«ã€Œç¸½ç²’æ•¸ã€èˆ‡ã€Œç¸½åŒ…æ•¸ã€ (Smart Jump é‚è¼¯)
    grand_total_grains = sum(global_total_grains_by_product.values())
    
    # å¾žä¸‹å¾€ä¸ŠæŽƒæ
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 20): # æŽƒæå‰ 20 æ¬„
            current_cell = ws.cell(row=r, column=c)
            val = str(current_cell.value).strip()
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºé—œéµå­—
            is_total_grains = "ç¸½ç²’æ•¸" in val
            is_total_packs = "ç¸½åŒ…æ•¸" in val
            
            if is_total_grains or is_total_packs:
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šåˆ¤æ–·è¦å¯«å…¥å“ªä¸€æ¬„ ---
                target_col = c + 1 # é è¨­æ˜¯å³é‚Šä¸€æ ¼
                
                # æª¢æŸ¥ç•¶å‰æ ¼å­ (æ¨™é¡Œæ ¼) æ˜¯å¦æœ‰è¢«åˆä½µ
                # å¦‚æžœæ˜¯ AB åˆä½µï¼Œé‚£ c=1 (A)ï¼Œä½†æˆ‘å€‘æ‡‰è©²è·³éŽ A, Bï¼Œå¯«å…¥ C (3)
                for rng in ws.merged_cells.ranges:
                    if current_cell.coordinate in rng:
                        # æ‰¾åˆ°äº†ï¼æ¨™é¡Œæ˜¯è¢«åˆä½µçš„
                        # æˆ‘å€‘çš„ç›®æ¨™æ˜¯ï¼šåˆä½µç¯„åœçš„æœ€å³é‚Š (max_col) çš„ä¸‹ä¸€æ ¼
                        target_col = rng.max_col + 1
                        break
                
                # å¯«å…¥æ­£ç¢ºçš„æ•¸å€¼
                if is_total_grains:
                    safe_write(ws, r, target_col, grand_total_grains)
                elif is_total_packs:
                    safe_write(ws, r, target_col, global_total_packs_all)

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    return output

# --- 3. Streamlit ä»‹é¢ (ç¶­æŒä¸è®Š) ---
st.set_page_config(page_title="æª³æ¦”å ±è¡¨ç”Ÿæˆå™¨ (v11 åº§æ¨™ä¿®æ­£ç‰ˆ)", layout="wide")
st.title("ðŸ­ æª³æ¦”éŠ·å”®å ±è¡¨è‡ªå‹•ç”Ÿæˆ")

DEFAULT_TEMPLATE = "æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx"

col1, col2 = st.columns([1, 2])
with col1:
    st.markdown("### 1. æ¨¡æ¿è¨­å®š")
    if os.path.exists(DEFAULT_TEMPLATE):
        st.success(f"âœ… ä½¿ç”¨é è¨­æ¨¡æ¿ï¼š{DEFAULT_TEMPLATE}")
        use_default = st.checkbox("ä½¿ç”¨é è¨­æ¨¡æ¿", value=True)
        template_file = DEFAULT_TEMPLATE if use_default else None
        if not use_default:
            template_file = st.file_uploader("ä¸Šå‚³æ–°æ¨¡æ¿", type=["xlsx"])
    else:
        st.warning("âš ï¸ è«‹ä¸Šå‚³ Excel æ¨¡æ¿")
        template_file = st.file_uploader("ä¸Šå‚³æ¨¡æ¿", type=["xlsx"])

with col2:
    st.markdown("### 2. åŽŸå§‹æ•¸æ“š")
    source_files = st.file_uploader("ä¸Šå‚³æ‰€æœ‰æ•¸æ“šæª”æ¡ˆ (æ”¯æ´ xls, xlsx, csv)", type=["csv", "xls", "xlsx"], accept_multiple_files=True)

default_grains = {
    "ç‰¹å¹¼": 8, "å¹¼å¤§å£": 8, "å¤šç²’": 12, "å¤šå¤§å£": 12,
    "å¹¼è": 10, "é›™å­æ˜Ÿ": 10, "å¤šè": 10, "æ™®é€š": 10
}

st.markdown("### 3. è¨­å®šæ¯åŒ…ç²’æ•¸")
cols = st.columns(4)
user_grains_setting = {}

for i, (product, default_val) in enumerate(default_grains.items()):
    with cols[i % 4]:
        val = st.number_input(f"{product}", value=default_val, step=1)
        user_grains_setting[product] = val

if st.button("ðŸš€ ç”Ÿæˆå ±è¡¨", type="primary"):
    current_template = template_file if template_file else (DEFAULT_TEMPLATE if os.path.exists(DEFAULT_TEMPLATE) else None)

    if not current_template:
        st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æª”æ¡ˆï¼")
    elif not source_files:
        st.error("è«‹ä¸Šå‚³åŽŸå§‹æ•¸æ“šæª”æ¡ˆã€‚")
    else:
        with st.spinner("æ­£åœ¨è§£æžèˆ‡è¨ˆç®—..."):
            all_data = []
            error_logs = []
            
            for f in source_files:
                df, msg = load_and_fix_smart(f)
                if df is not None:
                    all_data.append(df)
                else:
                    error_logs.append(f"âŒ {f.name}: {msg}")
            
            if error_logs:
                with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè®€å–å¤±æ•—"):
                    for log in error_logs:
                        st.code(log)
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                st.info(f"âœ… æˆåŠŸè®€å– {len(combined_df)} ç­†è³‡æ–™ã€‚")
                
                try:
                    result_excel = fill_excel_template(current_template, combined_df, user_grains_setting)
                    st.success("å ±è¡¨ç”ŸæˆæˆåŠŸï¼ç¸½ç²’æ•¸èˆ‡ç¸½åŒ…æ•¸ä½ç½®å·²ä¿®æ­£ã€‚")
                    st.download_button(
                        label="ðŸ“¥ ä¸‹è¼‰å ±è¡¨",
                        data=result_excel,
                        file_name="å·²å¡«å¯«_æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¡«å¯« Excel æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æˆåŠŸè®€å–ã€‚")
