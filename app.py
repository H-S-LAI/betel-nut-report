import streamlit as st
import pandas as pd
import io
import os
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell

# --- 1. æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨èƒ½è®€å–èˆ‡ä¿®å¾© ---
def load_and_fix_smart(uploaded_file):
    file_name = uploaded_file.name
    file_ext = os.path.splitext(file_name)[1].lower()
    df = None

    if file_ext in ['.xls', '.xlsx']:
        try:
            if file_ext == '.xls':
                df = pd.read_excel(uploaded_file, engine='xlrd')
            else:
                df = pd.read_excel(uploaded_file, engine='openpyxl')
        except Exception as e:
            return None, f"Excel è®€å–å¤±æ•—: {e}"
    else:
        bytes_data = uploaded_file.getvalue()
        content = ""
        try:
            text_utf8 = bytes_data.decode('utf-8')
            if 'Â©Â±' in text_utf8 or 'Â§O' in text_utf8: 
                content = text_utf8.encode('latin1', errors='ignore').decode('cp950', errors='ignore')
            else:
                content = text_utf8
        except:
            try:
                content = bytes_data.decode('cp950', errors='ignore')
            except:
                content = bytes_data.decode('latin1', errors='ignore')

        lines = content.splitlines()
        header_row_index = -1
        for i, line in enumerate(lines[:20]): 
            if "åº—å" in line and "å”®é‡" in line:
                header_row_index = i
                break
        if header_row_index == -1:
            return None, f"æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—ã€‚"

        try:
            valid_content = "\n".join(lines[header_row_index:])
            df = pd.read_csv(io.StringIO(valid_content))
        except Exception as e:
            return None, f"è§£æ CSV å¤±æ•—: {e}"

    if df is not None:
        try:
            target_df = pd.DataFrame()
            df.columns = [str(c).strip() for c in df.columns]

            if 'åº—å' in df.columns and 'å”®é‡' in df.columns:
                target_df = df
            elif df.shape[1] >= 4:
                target_df = df.iloc[:, [1, 2, 3]].copy()
                target_df.columns = ['åº—å', 'å“å', 'å”®é‡']
            else:
                return None, f"æ¬„ä½è­˜åˆ¥å¤±æ•—ã€‚"

            target_df['å”®é‡'] = pd.to_numeric(target_df['å”®é‡'], errors='coerce').fillna(0)
            target_df = target_df.dropna(subset=['åº—å'])
            target_df = target_df[target_df['åº—å'].astype(str).str.contains("åº—å") == False]
            return target_df, "Success"
        except Exception as e:
            return None, f"è³‡æ–™æ¨™æº–åŒ–å¤±æ•—: {e}"
    return None, "Unknown Error"

# --- åŠŸèƒ½ï¼šå®‰å…¨å¯«å…¥ ---
def safe_write(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        for rng in ws.merged_cells.ranges:
            if cell.coordinate in rng:
                top_left = ws.cell(row=rng.min_row, column=rng.min_col)
                top_left.value = value
                return
    else:
        cell.value = value

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šå¡«å¯« Excel (V15 é †åºæš´åŠ›å¡«å……ç‰ˆ) ---
def fill_excel_template_sequential(template_path_or_file, combined_df, grains_per_pack_map):
    if isinstance(template_path_or_file, str):
        wb = load_workbook(template_path_or_file)
    else:
        wb = load_workbook(template_path_or_file)
    ws = wb.active
    
    update_log = [] 

    # ==========================================
    # æ­¥é©Ÿ 1: æ•´ç†ä¾†æºæ•¸æ“š (æŒ‰ç”¢å“åˆ†çµ„ï¼Œä¿æŒé †åº)
    # ==========================================
    # çµæ§‹ï¼š { 'ç‰¹å¹¼': [100, 26, 66, ...], 'å¤šç²’': [25, 32, ...] }
    sales_lists_by_product = {}
    
    # é€™è£¡å‡è¨­ combined_df çš„é †åºå°±æ˜¯ user ä¸Šå‚³çš„é †åº (æˆ–æ˜¯ Excel è£¡çš„åŸå§‹é †åº)
    # ç‚ºäº†ä¿éšªï¼Œæˆ‘å€‘é‡å°æ¯ä¸€å€‹ product å»ºç«‹ä¸€å€‹åˆ—è¡¨
    
    # å–å¾—æ‰€æœ‰å‡ºç¾éçš„ç”¢å“
    unique_products = combined_df['å“å'].unique()
    
    for prod in unique_products:
        prod_key = str(prod).strip()
        # æ‰¾å‡ºè©²ç”¢å“çš„æ‰€æœ‰éŠ·å”®æ•¸æ“š (ä¾åŸå§‹é †åº)
        sales_series = combined_df[combined_df['å“å'] == prod]['å”®é‡'].tolist()
        
        # é€²è¡Œæ¨¡ç³ŠåŒ¹é…ï¼Œå°æ‡‰åˆ° grains_per_pack_map çš„ key
        matched_key = prod_key
        for key in grains_per_pack_map.keys():
            if key in prod_key:
                matched_key = key
                break
        
        if matched_key not in sales_lists_by_product:
            sales_lists_by_product[matched_key] = []
        
        sales_lists_by_product[matched_key].extend(sales_series)

    # ==========================================
    # æ­¥é©Ÿ 2: å®šä½ Excel çµæ§‹
    # ==========================================
    header_row = 3
    store_col_index = 1 
    
    for r in range(1, 10):
        found = False
        for c in range(1, 10):
            val = ws.cell(row=r, column=c).value
            if val and "åº—" in str(val):
                header_row = r
                store_col_index = c
                found = True
                break
        if found: break
    
    # æ‰¾å‡ºæ‰€æœ‰ (å“åæ¬„, å”®é‡æ¬„)
    col_pairs = [] 
    for c in range(1, ws.max_column + 1):
        val1 = str(ws.cell(row=header_row, column=c).value).strip()
        val2 = str(ws.cell(row=header_row, column=c+1).value).strip()
        if "å“å" in val1 and "å”®é‡" in val2:
            col_pairs.append((c, c+1))

    # ==========================================
    # æ­¥é©Ÿ 3: åˆå§‹åŒ– (æ¸…ç©ºèˆŠæ•¸æ“š) - Robust é—œéµ
    # ==========================================
    # æˆ‘å€‘æŠŠæ‰€æœ‰æ¬„ä½çš„å”®é‡éƒ½æ¸…ç©ºï¼Œé¿å…æ²’æœ‰è®€åˆ°çš„ç”¢å“æ®˜ç•™èˆŠå€¼
    for r in range(header_row + 1, ws.max_row + 1):
        cell_store = ws.cell(row=r, column=store_col_index).value
        if not cell_store or "éŠ·å”®" in str(cell_store) or "åˆè¨ˆ" in str(cell_store): continue
        
        for (prod_col, sales_col) in col_pairs:
             safe_write(ws, r, sales_col, 0) # å…ˆå…¨éƒ¨æ­¸é›¶

    # ==========================================
    # æ­¥é©Ÿ 4: æš´åŠ›ä¾åºå¡«å…… (Sequential Paste)
    # ==========================================
    # æˆ‘å€‘éœ€è¦çŸ¥é“ Excel è£¡çš„æ¯ä¸€å€‹ Column æ˜¯å±¬æ–¼å“ªå€‹ç”¢å“
    # é€™è£¡æ¡ç”¨å‹•æ…‹åµæ¸¬ï¼šæƒææ¯ä¸€è¡Œï¼Œçœ‹è©²ç”¢å“æ¬„ä½çš„å“åæ˜¯ä»€éº¼ï¼Œç„¶å¾Œå¾æ¸…å–®ä¸­æ‹¿å‡ºä¸‹ä¸€å€‹æ•¸å­—å¡«å…¥
    
    # ç‚ºäº†è™•ç†ã€Œå¤šè/æ™®é€šã€é€™ç¨®åªæœ‰éƒ¨åˆ†åº—æœ‰çš„æƒ…æ³ï¼š
    # å‡è¨­ Excel è£¡é€™æ¬„çš„æ ¼å­æ˜¯ç©ºçš„æˆ–æ˜¯ç‰¹å®šæ¨™è¨˜ï¼Ÿ
    # ä¸ï¼Œé€šå¸¸ Excel æ¨¡æ¿æ¯å€‹åº—éƒ½æœ‰æ ¼å­ã€‚
    # å¦‚æœä½¿ç”¨è€…èªª "ç…§é †åºè²¼"ï¼Œä»£è¡¨ä¾†æºè³‡æ–™çš„ç­†æ•¸ = Excel è£¡çš„åº—å®¶æ•¸ (æˆ–è€…å°æ‡‰çš„åº—å®¶æ•¸)
    # æˆ‘å€‘ç¶­è­·ä¸€å€‹ index æŒ‡æ¨™ï¼š { 'ç‰¹å¹¼': 0, 'å¤šç²’': 0 ... } æŒ‡å‘ç›®å‰å¡«åˆ°ç¬¬å¹¾å€‹æ•¸å­—
    
    current_idx_map = {k: 0 for k in sales_lists_by_product.keys()}
    
    for r in range(header_row + 1, ws.max_row + 1):
        cell_store = ws.cell(row=r, column=store_col_index).value
        
        if not cell_store: continue
        if "éŠ·å”®" in str(cell_store) or "åˆè¨ˆ" in str(cell_store): continue
        
        # å°é€™ä¸€åˆ—çš„æ¯ä¸€çµ„ (Prod, Sales)
        for (prod_col, sales_col) in col_pairs:
            cell_prod = ws.cell(row=r, column=prod_col).value
            if not cell_prod: continue
            prod_name_in_excel = str(cell_prod).strip()
            
            # è¾¨è­˜é€™æ˜¯å“ªå€‹ç”¢å“
            target_key = None
            for key in grains_per_pack_map.keys():
                if key in prod_name_in_excel:
                    target_key = key
                    break
            
            # å¦‚æœæˆ‘å€‘æ‰‹ä¸Šæœ‰é€™å€‹ç”¢å“çš„æ•¸æ“šæ¸…å–®
            if target_key and target_key in sales_lists_by_product:
                data_list = sales_lists_by_product[target_key]
                idx = current_idx_map[target_key]
                
                # é‚„æœ‰å½ˆè—¥å—ï¼Ÿ
                if idx < len(data_list):
                    val_to_write = data_list[idx]
                    safe_write(ws, r, sales_col, val_to_write)
                    current_idx_map[target_key] += 1 # æº–å‚™å¡«ä¸‹ä¸€å€‹
                else:
                    # å½ˆè—¥ç”¨ç›¡ (å¯èƒ½ä¾†æºè³‡æ–™æ¯” Excel åº—å®¶å°‘)ï¼Œä¿æŒ 0
                    pass

    # ==========================================
    # æ­¥é©Ÿ 5: çµ±è¨ˆèˆ‡çµç®— (åŒå‰ç‰ˆ)
    # ==========================================
    global_total_grains_by_product = {} 
    global_total_packs_all = 0

    pack_rows = []
    for r in range(1, ws.max_row + 1):
        val = ws.cell(row=r, column=store_col_index).value
        if val and "éŠ·å”®åŒ…æ•¸" in str(val):
            pack_rows.append(r)

    for r_pack in pack_rows:
        r_grain = -1
        next_cell = ws.cell(row=r_pack + 1, column=store_col_index).value
        if next_cell and "éŠ·å”®ç²’æ•¸" in str(next_cell):
            r_grain = r_pack + 1

        for (prod_col, sales_col) in col_pairs:
            found_product = None
            for offset in range(1, 6):
                val = ws.cell(row=r_pack - offset, column=prod_col).value
                if val and isinstance(val, str) and len(val) > 1:
                    for key in grains_per_pack_map.keys():
                        if key in val:
                            found_product = key
                            break
                    if found_product: break
            
            if found_product:
                setting_val = grains_per_pack_map.get(found_product)
                safe_write(ws, r_pack, prod_col, setting_val)
                
                # é‡æ–°è¨ˆç®—ç´…è‰²ç¸½å’Œ (å› ç‚ºæˆ‘å€‘å‰›å‰›å¡«å…¥äº†æ•¸æ“š)
                current_red_sum = 0
                for offset in range(1, 20):
                    r_scan = r_pack - offset
                    if r_scan <= header_row: break
                    val = ws.cell(row=r_scan, column=sales_col).value
                    if isinstance(val, (int, float)):
                        current_red_sum += val
                
                safe_write(ws, r_pack, sales_col, current_red_sum)
                global_total_packs_all += current_red_sum
                
                total_grains = current_red_sum * setting_val
                if r_grain != -1:
                    safe_write(ws, r_grain, sales_col, total_grains)
                
                if found_product not in global_total_grains_by_product:
                    global_total_grains_by_product[found_product] = 0
                global_total_grains_by_product[found_product] += total_grains

    # æ­¥é©Ÿ 6: ç¸½çµç®—
    row_summary = -1
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 10):
            val = str(ws.cell(row=r, column=c).value).strip()
            if "ç²’æ•¸ç¸½è¨ˆ" in val:
                row_summary = r
                break
        if row_summary != -1: break

    exclude_list = ["å¤šè", "æ™®é€š"]

    if row_summary != -1:
        for (prod_col, sales_col) in col_pairs:
            target_product = None
            if pack_rows:
                first_pack_row = pack_rows[0]
                for offset in range(1, 6):
                    val = ws.cell(row=first_pack_row - offset, column=prod_col).value
                    if val:
                         for key in grains_per_pack_map.keys():
                            if key in str(val):
                                target_product = key
                                break
                    if target_product: break
            
            if target_product and target_product not in exclude_list:
                val = global_total_grains_by_product.get(target_product, 0)
                safe_write(ws, row_summary, sales_col, val)
            else:
                safe_write(ws, row_summary, sales_col, "")

    # B. ç¸½ç²’æ•¸èˆ‡ç¸½åŒ…æ•¸
    grand_total_grains = sum(global_total_grains_by_product.values())
    
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 20): 
            current_cell = ws.cell(row=r, column=c)
            val = str(current_cell.value).strip()
            
            is_total_grains = "ç¸½ç²’æ•¸" in val
            is_total_packs = "ç¸½åŒ…æ•¸" in val
            
            if is_total_grains or is_total_packs:
                target_col = c + 1
                for rng in ws.merged_cells.ranges:
                    if current_cell.coordinate in rng:
                        target_col = rng.max_col + 1
                        break
                
                if is_total_grains:
                    safe_write(ws, r, target_col, grand_total_grains)
                elif is_total_packs:
                    safe_write(ws, r, target_col, global_total_packs_all)

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    return output, update_log

# --- 3. Streamlit ä»‹é¢ ---
st.set_page_config(page_title="æª³æ¦”å ±è¡¨ç”Ÿæˆå™¨ (v15 é †åºæš´åŠ›å¡«å……ç‰ˆ)", layout="wide")
st.title("ğŸ­ æª³æ¦”éŠ·å”®å ±è¡¨è‡ªå‹•ç”Ÿæˆ")

DEFAULT_TEMPLATE = "æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx"

col1, col2 = st.columns([1, 2])
with col1:
    st.markdown("### 1. æ¨¡æ¿è¨­å®š")
    if os.path.exists(DEFAULT_TEMPLATE):
        st.success(f"âœ… ä½¿ç”¨é è¨­æ¨¡æ¿ï¼š{DEFAULT_TEMPLATE}")
        use_default = st.checkbox("ä½¿ç”¨é è¨­æ¨¡æ¿", value=True)
        template_file = DEFAULT_TEMPLATE if use_default else None
        if not use_default:
            template_file = st.file_uploader("ä¸Šå‚³æ–°æ¨¡æ¿", type=["xlsx"])
    else:
        st.warning("âš ï¸ è«‹ä¸Šå‚³ Excel æ¨¡æ¿")
        template_file = st.file_uploader("ä¸Šå‚³æ¨¡æ¿", type=["xlsx"])

with col2:
    st.markdown("### 2. åŸå§‹æ•¸æ“š")
    source_files = st.file_uploader("ä¸Šå‚³æ‰€æœ‰æ•¸æ“šæª”æ¡ˆ (æ”¯æ´ xls, xlsx, csv)", type=["csv", "xls", "xlsx"], accept_multiple_files=True)

default_grains = {
    "ç‰¹å¹¼": 8, "å¹¼å¤§å£": 8, "å¤šç²’": 12, "å¤šå¤§å£": 12,
    "å¹¼è": 10, "é›™å­æ˜Ÿ": 10, "å¤šè": 10, "æ™®é€š": 10
}

st.markdown("### 3. è¨­å®šæ¯åŒ…ç²’æ•¸")
cols = st.columns(4)
user_grains_setting = {}

for i, (product, default_val) in enumerate(default_grains.items()):
    with cols[i % 4]:
        val = st.number_input(f"{product}", value=default_val, step=1)
        user_grains_setting[product] = val

if st.button("ğŸš€ ç”Ÿæˆå ±è¡¨", type="primary"):
    current_template = template_file if template_file else (DEFAULT_TEMPLATE if os.path.exists(DEFAULT_TEMPLATE) else None)

    if not current_template:
        st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æª”æ¡ˆï¼")
    elif not source_files:
        st.error("è«‹ä¸Šå‚³åŸå§‹æ•¸æ“šæª”æ¡ˆã€‚")
    else:
        with st.spinner("æ­£åœ¨è§£æèˆ‡è¨ˆç®—..."):
            all_data = []
            error_logs = []
            
            for f in source_files:
                df, msg = load_and_fix_smart(f)
                if df is not None:
                    df['ä¾†æºæª”æ¡ˆ'] = f.name 
                    all_data.append(df)
                else:
                    error_logs.append(f"âŒ {f.name}: {msg}")
            
            if error_logs:
                with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè®€å–å¤±æ•—"):
                    for log in error_logs:
                        st.code(log)
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                st.info(f"âœ… æˆåŠŸè®€å– {len(combined_df)} ç­†è³‡æ–™ã€‚")
                
                with st.expander("ğŸ” æŸ¥çœ‹è®€å–æ•¸æ“šè©³æƒ… (ç¢ºèªé †åºæ˜¯å¦æ­£ç¢º)"):
                    st.dataframe(combined_df)

                try:
                    result_excel, logs = fill_excel_template_sequential(current_template, combined_df, user_grains_setting)
                    st.success("å ±è¡¨ç”ŸæˆæˆåŠŸï¼å·²ä½¿ç”¨é †åºå¼·åˆ¶å¡«å……æ¨¡å¼ã€‚")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å ±è¡¨",
                        data=result_excel,
                        file_name="å·²å¡«å¯«_æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¡«å¯« Excel æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æˆåŠŸè®€å–ã€‚")
