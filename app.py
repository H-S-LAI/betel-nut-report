import streamlit as st
import pandas as pd
import io
import os
from openpyxl import load_workbook

# --- 1. æ ¸å¿ƒåŠŸèƒ½ï¼šæ™ºæ…§è®€å–èˆ‡ä¿®å¾© ---
def load_and_fix_csv_smart(uploaded_file):
    """
    1. å˜—è©¦ä¿®å¾©äº‚ç¢¼ (UTF-8 -> CP950)
    2. è‡ªå‹•å°‹æ‰¾ã€Œåº—åã€æ‰€åœ¨çš„è¡Œæ•¸ï¼Œè·³éä¸Šæ–¹çš„æ¨™é¡Œé›œè¨Š
    """
    file_name = uploaded_file.name
    bytes_data = uploaded_file.getvalue()
    
    # -----------------------
    # A. è§£ç¢¼éšæ®µ (Decoding)
    # -----------------------
    content = ""
    decoded_method = ""
    
    # ç­–ç•¥ 1: é‡å°ä½ çš„æª”æ¡ˆç‰¹å¾µ (Double Encoded)
    # ä½ çš„æª”æ¡ˆçœ‹èµ·ä¾†æ˜¯è¢« UTF-8 åŒ…è£éçš„ Big5
    try:
        text_utf8 = bytes_data.decode('utf-8')
        if 'Â©Â±' in text_utf8 or 'Â§O' in text_utf8: 
            # å˜—è©¦é‚„åŸäº‚ç¢¼
            content = text_utf8.encode('latin1', errors='ignore').decode('cp950', errors='ignore')
            decoded_method = "Mojibake Fix"
        else:
            content = text_utf8
            decoded_method = "UTF-8"
    except:
        # ç­–ç•¥ 2: ç›´æ¥å˜—è©¦ CP950
        try:
            content = bytes_data.decode('cp950', errors='ignore')
            decoded_method = "CP950"
        except:
            # ç­–ç•¥ 3: Latin1 (ä¿åº•ï¼Œçµ•ä¸å ±éŒ¯)
            content = bytes_data.decode('latin1', errors='ignore')
            decoded_method = "Latin1"

    # -----------------------
    # B. æ¨™é¡Œå®šä½ (Header Detection)
    # -----------------------
    # æˆ‘å€‘å°‡å…§å®¹åˆ‡æˆè¡Œï¼Œå°‹æ‰¾ "åº—å" åœ¨å“ªä¸€è¡Œ
    lines = content.splitlines()
    header_row_index = -1
    
    for i, line in enumerate(lines[:20]): # åªæ‰¾å‰ 20 è¡Œ
        if "åº—å" in line and "å”®é‡" in line:
            header_row_index = i
            break
            
    if header_row_index == -1:
        # æ‰¾ä¸åˆ° headerï¼Œå¯èƒ½æ˜¯ç·¨ç¢¼å¾¹åº•å¤±æ•—ï¼Œå›å‚³ raw content ä¾›é™¤éŒ¯
        return None, f"æ‰¾ä¸åˆ°æ¨™é¡Œåˆ— (ä½¿ç”¨ {decoded_method} è§£ç¢¼)ã€‚å‰ 100 å­—é è¦½ï¼š\n{content[:100]}"

    # -----------------------
    # C. è®€å–æ•¸æ“š
    # -----------------------
    try:
        # é‡çµ„å¾ header é–‹å§‹çš„å…§å®¹
        valid_content = "\n".join(lines[header_row_index:])
        
        # è®€å– CSV
        df = pd.read_csv(io.StringIO(valid_content))
        
        # æª¢æŸ¥æ¬„ä½
        # ä½ çš„æª”æ¡ˆçµæ§‹ï¼šç¬¬2æ¬„=åº—å, ç¬¬3æ¬„=å“å, ç¬¬4æ¬„=å”®é‡
        # å› ç‚ºæˆ‘å€‘å·²ç¶“å¾ header é–‹å§‹è®€ï¼Œæ‰€ä»¥æ¬„ä½åç¨±æ‡‰è©²å·²ç¶“æ­£ç¢ºæŠ“åˆ°äº† (æˆ–è€…åœ¨ç¬¬ä¸€è¡Œ)
        
        # æœ‰æ™‚å€™ header é‚£ä¸€è¡Œæœ¬èº«ä¹Ÿæœ‰äº‚ç¢¼ï¼Œæˆ‘å€‘æª¢æŸ¥æ¬„ä½æ˜¯å¦åŒ…å«é—œéµå­—
        # å¦‚æœæ¬„ä½åä¸å°ï¼Œæˆ‘å€‘å˜—è©¦ç”¨ index å¼·åˆ¶é–å®š
        
        # å»ºç«‹æ¨™æº–æ¬„ä½å
        target_df = pd.DataFrame()
        
        # ç‹€æ³ 1: æ¬„ä½åç¨±æ­£ç¢ºè®€å–
        if 'åº—å' in df.columns and 'å”®é‡' in df.columns:
            target_df = df
        # ç‹€æ³ 2: æ¬„ä½åç¨±äº‚æ‰ï¼Œä½†æ¬„ä½æ•¸é‡å¤  (é€šå¸¸ index 1 æ˜¯åº—å, 2 æ˜¯å“å, 3 æ˜¯å”®é‡)
        elif df.shape[1] >= 4:
            target_df = df.iloc[:, [1, 2, 3]].copy()
            target_df.columns = ['åº—å', 'å“å', 'å”®é‡']
        else:
             return None, f"æ¬„ä½æ•¸é‡ä¸è¶³ ({df.shape[1]})"

        # æœ€å¾Œæ¸…ç†
        target_df['å”®é‡'] = pd.to_numeric(target_df['å”®é‡'], errors='coerce').fillna(0)
        target_df = target_df.dropna(subset=['åº—å'])
        
        # éæ¿¾æ‰å¯èƒ½é‡è¤‡è®€åˆ°çš„æ¨™é¡Œè¡Œ
        target_df = target_df[target_df['åº—å'].astype(str).str.contains("åº—å") == False]
        
        return target_df, "Success"

    except Exception as e:
        return None, f"è§£æ CSV å¤±æ•—: {e}"

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šå¡«å¯« Excel (ç¶­æŒä¸è®Š) ---
def fill_excel_template(template_path_or_file, combined_df, grains_per_pack_map):
    if isinstance(template_path_or_file, str):
        wb = load_workbook(template_path_or_file)
    else:
        wb = load_workbook(template_path_or_file)
    ws = wb.active

    data_dict = {}
    for index, row in combined_df.iterrows():
        store = str(row['åº—å']).strip()
        product = str(row['å“å']).strip()
        sales = row['å”®é‡']
        
        if store not in data_dict:
            data_dict[store] = {}
        data_dict[store][product] = data_dict[store].get(product, 0) + sales

    # å®šä½ Header
    header_row = 3
    for r in range(1, 10):
        val = ws.cell(row=r, column=1).value
        if val and "åº—" in str(val):
            header_row = r
            break
            
    product_col_map = {}
    for col in range(2, ws.max_column + 1):
        val = ws.cell(row=header_row, column=col).value
        if val and isinstance(val, str):
            product_name = val.strip()
            if "å”®" not in product_name and product_name in grains_per_pack_map:
                product_col_map[product_name] = col

    total_sales_packs = {p: 0 for p in product_col_map}
    row_packs = None
    row_grains = None
    
    for row in range(header_row + 1, ws.max_row + 1):
        cell_val = ws.cell(row=row, column=1).value
        if not cell_val:
            continue
        row_label = str(cell_val).strip()
        
        if "éŠ·å”®åŒ…æ•¸" in row_label:
            row_packs = row
            continue
        if "éŠ·å”®ç²’æ•¸" in row_label:
            row_grains = row
            continue
            
        if row_label in data_dict:
            for product, col_idx in product_col_map.items():
                if product in data_dict[row_label]:
                    val = data_dict[row_label][product]
                    ws.cell(row=row, column=col_idx + 1).value = val
                    total_sales_packs[product] += val

    if row_packs:
        for product, col_idx in product_col_map.items():
            grains_setting = grains_per_pack_map.get(product, 0)
            ws.cell(row=row_packs, column=col_idx).value = grains_setting
            
            total_packs = total_sales_packs.get(product, 0)
            ws.cell(row=row_packs, column=col_idx + 1).value = total_packs

            if row_grains:
                total_grains = total_packs * grains_setting
                ws.cell(row=row_grains, column=col_idx + 1).value = total_grains

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    return output

# --- 3. Streamlit ä»‹é¢ ---
st.set_page_config(page_title="æª³æ¦”å ±è¡¨ç”Ÿæˆå™¨ (v6 çµ‚æ¥µç‰ˆ)", layout="wide")
st.title("ğŸ­ æª³æ¦”éŠ·å”®å ±è¡¨è‡ªå‹•ç”Ÿæˆ")

DEFAULT_TEMPLATE = "æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx"

col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### 1. æ¨¡æ¿è¨­å®š")
    if os.path.exists(DEFAULT_TEMPLATE):
        st.success(f"âœ… ä½¿ç”¨é è¨­æ¨¡æ¿ï¼š{DEFAULT_TEMPLATE}")
        use_default = st.checkbox("ä½¿ç”¨é è¨­æ¨¡æ¿", value=True)
        template_file = DEFAULT_TEMPLATE if use_default else None
        if not use_default:
            template_file = st.file_uploader("ä¸Šå‚³æ–°æ¨¡æ¿", type=["xlsx"])
    else:
        st.warning("âš ï¸ è«‹ä¸Šå‚³ Excel æ¨¡æ¿")
        template_file = st.file_uploader("ä¸Šå‚³æ¨¡æ¿", type=["xlsx"])

with col2:
    st.markdown("### 2. åŸå§‹æ•¸æ“š")
    source_files = st.file_uploader("ä¸Šå‚³æ‰€æœ‰æ•¸æ“šæª”æ¡ˆ", type=["csv", "xls"], accept_multiple_files=True)

default_grains = {
    "ç‰¹å¹¼": 8, "å¹¼å¤§å£": 8, "å¤šç²’": 12, "å¤šå¤§å£": 12,
    "å¹¼è": 10, "é›™å­æ˜Ÿ": 10, "å¤šè": 10, "æ™®é€š": 10
}

st.markdown("### 3. è¨­å®šæ¯åŒ…ç²’æ•¸")
cols = st.columns(4)
user_grains_setting = {}

for i, (product, default_val) in enumerate(default_grains.items()):
    with cols[i % 4]:
        val = st.number_input(f"{product}", value=default_val, step=1)
        user_grains_setting[product] = val

if st.button("ğŸš€ ç”Ÿæˆå ±è¡¨", type="primary"):
    current_template = template_file if template_file else (DEFAULT_TEMPLATE if os.path.exists(DEFAULT_TEMPLATE) else None)

    if not current_template:
        st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æª”æ¡ˆï¼")
    elif not source_files:
        st.error("è«‹ä¸Šå‚³åŸå§‹æ•¸æ“šæª”æ¡ˆã€‚")
    else:
        with st.spinner("æ­£åœ¨è§£ææ•¸æ“š..."):
            all_data = []
            error_logs = []
            
            for f in source_files:
                df, msg = load_and_fix_csv_smart(f)
                if df is not None:
                    all_data.append(df)
                else:
                    error_logs.append(f"âŒ {f.name}: {msg}")
            
            # é¡¯ç¤ºéŒ¯èª¤æ—¥èªŒ (å¦‚æœæœ‰)
            if error_logs:
                with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè®€å–å¤±æ•— (é»æ“ŠæŸ¥çœ‹è©³æƒ…)"):
                    for log in error_logs:
                        st.code(log)
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                st.info(f"âœ… æˆåŠŸè®€å– {len(combined_df)} ç­†è³‡æ–™ã€‚")
                
                try:
                    result_excel = fill_excel_template(current_template, combined_df, user_grains_setting)
                    st.success("å ±è¡¨ç”ŸæˆæˆåŠŸï¼")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å ±è¡¨",
                        data=result_excel,
                        file_name="å·²å¡«å¯«_æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¡«å¯« Excel æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æˆåŠŸè®€å–ã€‚è«‹æŸ¥çœ‹ä¸Šæ–¹çš„éŒ¯èª¤æ—¥èªŒã€‚")
