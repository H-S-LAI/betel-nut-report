import streamlit as st
import pandas as pd
import io
import os
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell

# --- 1. æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨èƒ½è®€å–èˆ‡ä¿®å¾© ---
def load_and_fix_smart(uploaded_file):
    file_name = uploaded_file.name
    file_ext = os.path.splitext(file_name)[1].lower()
    df = None

    if file_ext in ['.xls', '.xlsx']:
        try:
            if file_ext == '.xls':
                df = pd.read_excel(uploaded_file, engine='xlrd')
            else:
                df = pd.read_excel(uploaded_file, engine='openpyxl')
        except Exception as e:
            return None, f"Excel è®€å–å¤±æ•—: {e}"
    else:
        bytes_data = uploaded_file.getvalue()
        content = ""
        try:
            text_utf8 = bytes_data.decode('utf-8')
            if 'Â©Â±' in text_utf8 or 'Â§O' in text_utf8: 
                content = text_utf8.encode('latin1', errors='ignore').decode('cp950', errors='ignore')
            else:
                content = text_utf8
        except:
            try:
                content = bytes_data.decode('cp950', errors='ignore')
            except:
                content = bytes_data.decode('latin1', errors='ignore')

        lines = content.splitlines()
        header_row_index = -1
        for i, line in enumerate(lines[:20]): 
            if "åº—å" in line and "å”®é‡" in line:
                header_row_index = i
                break
        if header_row_index == -1:
            return None, f"æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—ã€‚"

        try:
            valid_content = "\n".join(lines[header_row_index:])
            df = pd.read_csv(io.StringIO(valid_content))
        except Exception as e:
            return None, f"è§£æ CSV å¤±æ•—: {e}"

    if df is not None:
        try:
            target_df = pd.DataFrame()
            df.columns = [str(c).strip() for c in df.columns]

            if 'åº—å' in df.columns and 'å”®é‡' in df.columns:
                target_df = df
            elif df.shape[1] >= 4:
                target_df = df.iloc[:, [1, 2, 3]].copy()
                target_df.columns = ['åº—å', 'å“å', 'å”®é‡']
            else:
                return None, f"æ¬„ä½è­˜åˆ¥å¤±æ•—ã€‚"

            target_df['å”®é‡'] = pd.to_numeric(target_df['å”®é‡'], errors='coerce').fillna(0)
            target_df = target_df.dropna(subset=['åº—å'])
            target_df = target_df[target_df['åº—å'].astype(str).str.contains("åº—å") == False]
            return target_df, "Success"
        except Exception as e:
            return None, f"è³‡æ–™æ¨™æº–åŒ–å¤±æ•—: {e}"
    return None, "Unknown Error"

# --- åŠŸèƒ½ï¼šå®‰å…¨å¯«å…¥ ---
def safe_write(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        for rng in ws.merged_cells.ranges:
            if cell.coordinate in rng:
                top_left = ws.cell(row=rng.min_row, column=rng.min_col)
                top_left.value = value
                return
    else:
        cell.value = value

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šå¡«å¯« Excel (V12 ç²¾æº–æ¬„ä½ç‰ˆ) ---
def fill_excel_template(template_path_or_file, combined_df, grains_per_pack_map):
    if isinstance(template_path_or_file, str):
        wb = load_workbook(template_path_or_file)
    else:
        wb = load_workbook(template_path_or_file)
    ws = wb.active

    # ==========================================
    # æº–å‚™å·¥ä½œ
    # ==========================================
    global_total_grains_by_product = {} 
    global_total_packs_all = 0
    
    # é—œéµä¿®æ­£ï¼šåªç´€éŒ„ã€Œæ•¸å€¼æ¬„ä½ (Value Columns)ã€ä¾†å¡«å¯«ç¸½è¨ˆ
    value_column_map = {} # col_index -> product_name

    # 1. æ•´ç†éŠ·å”®æ•¸æ“š
    data_dict = {}
    for index, row in combined_df.iterrows():
        store = str(row['åº—å']).strip()
        product = str(row['å“å']).strip()
        sales = row['å”®é‡']
        
        if store not in data_dict:
            data_dict[store] = {}
        
        matched_key = product
        for key in grains_per_pack_map.keys():
            if key in product:
                matched_key = key
                break
        data_dict[store][matched_key] = data_dict[store].get(matched_key, 0) + sales

    # å®šä½ Header
    header_row = 3
    for r in range(1, 10):
        val = ws.cell(row=r, column=1).value
        if val and "åº—" in str(val):
            header_row = r
            break
            
    # 2. å¡«å¯«åˆ†åº—æ•¸æ“š
    store_cols = []
    for col in range(1, ws.max_column + 1):
        val = ws.cell(row=header_row, column=col).value
        if val and "åº—" in str(val):
            store_cols.append(col)

    for store_col in store_cols:
        prod_col = store_col + 1
        sales_col = store_col + 2
        
        for r in range(header_row + 1, ws.max_row + 1):
            cell_store = ws.cell(row=r, column=store_col).value
            if not cell_store or "éŠ·å”®" in str(cell_store):
                continue
            
            store_name = str(cell_store).strip()
            cell_prod = ws.cell(row=r, column=prod_col).value
            if not cell_prod:
                continue
            prod_name_in_excel = str(cell_prod).strip()
            
            if store_name in data_dict:
                sales_val = 0
                for key_prod in data_dict[store_name]:
                    if key_prod in prod_name_in_excel or prod_name_in_excel in key_prod:
                        sales_val = data_dict[store_name][key_prod]
                        break
                # å¼·åˆ¶æ›´æ–°ï¼šå³ä½¿æ˜¯ 0 ä¹Ÿè¦çœ‹æƒ…æ³ï¼Œä½†é€šå¸¸åªæ›´æ–° > 0ï¼Œé™¤éè¦æ¸…ç©º
                if sales_val > 0:
                    safe_write(ws, r, sales_col, sales_val)

    # ==========================================
    # 3. è™•ç†ã€Œç´…è‰²åŒ…æ•¸ã€èˆ‡ã€Œè—è‰²ç²’æ•¸ã€
    # ==========================================
    pack_rows = []
    for r in range(1, ws.max_row + 1):
        val = ws.cell(row=r, column=1).value
        if val and "éŠ·å”®åŒ…æ•¸" in str(val):
            pack_rows.append(r)

    for r_pack in pack_rows:
        r_grain = -1
        if ws.cell(row=r_pack + 1, column=1).value and "éŠ·å”®ç²’æ•¸" in str(ws.cell(row=r_pack + 1, column=1).value):
            r_grain = r_pack + 1

        for col in range(1, ws.max_column + 1):
            found_product = None
            # å¾€ä¸Šçœ‹æ‰¾ç”¢å“å
            for offset in range(1, 6):
                val = ws.cell(row=r_pack - offset, column=col).value
                if val and isinstance(val, str) and len(val) > 1:
                    for key in grains_per_pack_map.keys():
                        if key in val:
                            found_product = key
                            break
                    if found_product:
                        break
            
            if found_product:
                # é€™è£¡å¾ˆé—œéµï¼šfound_product æ˜¯åœ¨ col é€™ä¸€æ¬„æ‰¾åˆ°çš„ (ä¹Ÿå°±æ˜¯å“å/è¨­å®šæ¬„)
                # çœŸæ­£çš„éŠ·å”®æ•¸å­—æ˜¯åœ¨ col + 1 (å³é‚Šé‚£æ¬„)
                value_col = col + 1
                value_column_map[value_col] = found_product

                # 1. æ›´æ–°ç¶ è‰² (ç²’æ•¸è¨­å®š) - åœ¨ col
                setting_val = grains_per_pack_map.get(found_product)
                safe_write(ws, r_pack, col, setting_val)
                
                # 2. è¨ˆç®—ç´…è‰² - åœ¨ col + 1 (value_col)
                current_red_sum = 0
                for offset in range(1, 20):
                    r_scan = r_pack - offset
                    if r_scan <= header_row: break
                    val = ws.cell(row=r_scan, column=value_col).value
                    if isinstance(val, (int, float)):
                        current_red_sum += val
                
                # å¯«å…¥ç´…è‰²
                safe_write(ws, r_pack, value_col, current_red_sum)
                global_total_packs_all += current_red_sum

                # 3. å¯«å…¥è—è‰² - åœ¨ col + 1 (value_col)
                total_grains = current_red_sum * setting_val
                if r_grain != -1:
                    safe_write(ws, r_grain, value_col, total_grains)
                
                if found_product not in global_total_grains_by_product:
                    global_total_grains_by_product[found_product] = 0
                global_total_grains_by_product[found_product] += total_grains

    # ==========================================
    # 4. è™•ç†ã€Œç²’æ•¸ç¸½è¨ˆã€ (åªå¡«å¯«å”®é‡æ¬„ä½)
    # ==========================================
    
    row_summary = -1
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 10):
            val = str(ws.cell(row=r, column=c).value).strip()
            if "ç²’æ•¸ç¸½è¨ˆ" in val:
                row_summary = r
                break
        if row_summary != -1: break

    # A. å¡«å¯«ã€Œç²’æ•¸ç¸½è¨ˆã€åˆ—
    exclude_list = ["å¤šè", "æ™®é€š"]
    if row_summary != -1:
        # åªéæ­·æˆ‘å€‘æ¨™è¨˜éçš„ã€Œæ•¸å€¼æ¬„ä½ã€ (value_column_map)
        for col, prod_name in value_column_map.items():
            if prod_name not in exclude_list:
                val = global_total_grains_by_product.get(prod_name, 0)
                safe_write(ws, row_summary, col, val)
            else:
                safe_write(ws, row_summary, col, "")

    # B. å¡«å¯«ã€Œç¸½ç²’æ•¸ã€èˆ‡ã€Œç¸½åŒ…æ•¸ã€
    grand_total_grains = sum(global_total_grains_by_product.values())
    
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 20): 
            current_cell = ws.cell(row=r, column=c)
            val = str(current_cell.value).strip()
            
            is_total_grains = "ç¸½ç²’æ•¸" in val
            is_total_packs = "ç¸½åŒ…æ•¸" in val
            
            if is_total_grains or is_total_packs:
                target_col = c + 1
                for rng in ws.merged_cells.ranges:
                    if current_cell.coordinate in rng:
                        target_col = rng.max_col + 1
                        break
                
                if is_total_grains:
                    safe_write(ws, r, target_col, grand_total_grains)
                elif is_total_packs:
                    safe_write(ws, r, target_col, global_total_packs_all)

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    return output

# --- 3. Streamlit ä»‹é¢ ---
st.set_page_config(page_title="æª³æ¦”å ±è¡¨ç”Ÿæˆå™¨ (v12 æ•¸æ“šé€è¦–ç‰ˆ)", layout="wide")
st.title("ğŸ­ æª³æ¦”éŠ·å”®å ±è¡¨è‡ªå‹•ç”Ÿæˆ")

DEFAULT_TEMPLATE = "æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx"

col1, col2 = st.columns([1, 2])
with col1:
    st.markdown("### 1. æ¨¡æ¿è¨­å®š")
    if os.path.exists(DEFAULT_TEMPLATE):
        st.success(f"âœ… ä½¿ç”¨é è¨­æ¨¡æ¿ï¼š{DEFAULT_TEMPLATE}")
        use_default = st.checkbox("ä½¿ç”¨é è¨­æ¨¡æ¿", value=True)
        template_file = DEFAULT_TEMPLATE if use_default else None
        if not use_default:
            template_file = st.file_uploader("ä¸Šå‚³æ–°æ¨¡æ¿", type=["xlsx"])
    else:
        st.warning("âš ï¸ è«‹ä¸Šå‚³ Excel æ¨¡æ¿")
        template_file = st.file_uploader("ä¸Šå‚³æ¨¡æ¿", type=["xlsx"])

with col2:
    st.markdown("### 2. åŸå§‹æ•¸æ“š")
    source_files = st.file_uploader("ä¸Šå‚³æ‰€æœ‰æ•¸æ“šæª”æ¡ˆ (æ”¯æ´ xls, xlsx, csv)", type=["csv", "xls", "xlsx"], accept_multiple_files=True)

default_grains = {
    "ç‰¹å¹¼": 8, "å¹¼å¤§å£": 8, "å¤šç²’": 12, "å¤šå¤§å£": 12,
    "å¹¼è": 10, "é›™å­æ˜Ÿ": 10, "å¤šè": 10, "æ™®é€š": 10
}

st.markdown("### 3. è¨­å®šæ¯åŒ…ç²’æ•¸")
cols = st.columns(4)
user_grains_setting = {}

for i, (product, default_val) in enumerate(default_grains.items()):
    with cols[i % 4]:
        val = st.number_input(f"{product}", value=default_val, step=1)
        user_grains_setting[product] = val

if st.button("ğŸš€ ç”Ÿæˆå ±è¡¨", type="primary"):
    current_template = template_file if template_file else (DEFAULT_TEMPLATE if os.path.exists(DEFAULT_TEMPLATE) else None)

    if not current_template:
        st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æª”æ¡ˆï¼")
    elif not source_files:
        st.error("è«‹ä¸Šå‚³åŸå§‹æ•¸æ“šæª”æ¡ˆã€‚")
    else:
        with st.spinner("æ­£åœ¨è§£æèˆ‡è¨ˆç®—..."):
            all_data = []
            error_logs = []
            
            for f in source_files:
                df, msg = load_and_fix_smart(f)
                if df is not None:
                    # ç´€éŒ„ä¾†æºæª”åï¼Œæ–¹ä¾¿æ’æŸ¥
                    df['ä¾†æºæª”æ¡ˆ'] = f.name 
                    all_data.append(df)
                else:
                    error_logs.append(f"âŒ {f.name}: {msg}")
            
            if error_logs:
                with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè®€å–å¤±æ•—"):
                    for log in error_logs:
                        st.code(log)
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                st.info(f"âœ… æˆåŠŸè®€å– {len(combined_df)} ç­†è³‡æ–™ã€‚")
                
                # --- æ–°å¢ï¼šæ•¸æ“šæª¢æŸ¥å€ ---
                with st.expander("ğŸ” é»æ“Šé€™è£¡æŸ¥çœ‹ç¨‹å¼è®€åˆ°çš„è©³ç´°æ•¸æ“š (æª¢æŸ¥ 24 æœ‰æ²’æœ‰è®Š 100)"):
                    st.dataframe(combined_df)
                # ---------------------

                try:
                    result_excel = fill_excel_template(current_template, combined_df, user_grains_setting)
                    st.success("å ±è¡¨ç”ŸæˆæˆåŠŸï¼ç²’æ•¸ç¸½è¨ˆå·²ä¿®æ­£ä½ç½®ã€‚")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å ±è¡¨",
                        data=result_excel,
                        file_name="å·²å¡«å¯«_æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¡«å¯« Excel æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æˆåŠŸè®€å–ã€‚")
