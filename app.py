import streamlit as st
import pandas as pd
import io
import os
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell

# --- 1. æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨èƒ½è®€å–èˆ‡ä¿®å¾© (ç¶­æŒä¸è®Š) ---
def load_and_fix_smart(uploaded_file):
    file_name = uploaded_file.name
    file_ext = os.path.splitext(file_name)[1].lower()
    df = None

    if file_ext in ['.xls', '.xlsx']:
        try:
            if file_ext == '.xls':
                df = pd.read_excel(uploaded_file, engine='xlrd')
            else:
                df = pd.read_excel(uploaded_file, engine='openpyxl')
        except Exception as e:
            return None, f"Excel è®€å–å¤±æ•—: {e}"
    else:
        bytes_data = uploaded_file.getvalue()
        content = ""
        try:
            text_utf8 = bytes_data.decode('utf-8')
            if 'Â©Â±' in text_utf8 or 'Â§O' in text_utf8: 
                content = text_utf8.encode('latin1', errors='ignore').decode('cp950', errors='ignore')
            else:
                content = text_utf8
        except:
            try:
                content = bytes_data.decode('cp950', errors='ignore')
            except:
                content = bytes_data.decode('latin1', errors='ignore')

        lines = content.splitlines()
        header_row_index = -1
        for i, line in enumerate(lines[:20]): 
            if "åº—å" in line and "å”®é‡" in line:
                header_row_index = i
                break
        if header_row_index == -1:
            return None, f"æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—ã€‚"

        try:
            valid_content = "\n".join(lines[header_row_index:])
            df = pd.read_csv(io.StringIO(valid_content))
        except Exception as e:
            return None, f"è§£æ CSV å¤±æ•—: {e}"

    if df is not None:
        try:
            target_df = pd.DataFrame()
            df.columns = [str(c).strip() for c in df.columns]

            if 'åº—å' in df.columns and 'å”®é‡' in df.columns:
                target_df = df
            elif df.shape[1] >= 4:
                target_df = df.iloc[:, [1, 2, 3]].copy()
                target_df.columns = ['åº—å', 'å“å', 'å”®é‡']
            else:
                return None, f"æ¬„ä½è­˜åˆ¥å¤±æ•—ã€‚"

            target_df['å”®é‡'] = pd.to_numeric(target_df['å”®é‡'], errors='coerce').fillna(0)
            target_df = target_df.dropna(subset=['åº—å'])
            target_df = target_df[target_df['åº—å'].astype(str).str.contains("åº—å") == False]
            return target_df, "Success"
        except Exception as e:
            return None, f"è³‡æ–™æ¨™æº–åŒ–å¤±æ•—: {e}"
    return None, "Unknown Error"

# --- åŠŸèƒ½ï¼šå®‰å…¨å¯«å…¥ ---
def safe_write(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        for rng in ws.merged_cells.ranges:
            if cell.coordinate in rng:
                top_left = ws.cell(row=rng.min_row, column=rng.min_col)
                top_left.value = value
                return
    else:
        cell.value = value

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šå¡«å¯« Excel (V13 å¯¬ç‰ˆæƒææ¶æ§‹) ---
def fill_excel_template(template_path_or_file, combined_df, grains_per_pack_map):
    if isinstance(template_path_or_file, str):
        wb = load_workbook(template_path_or_file)
    else:
        wb = load_workbook(template_path_or_file)
    ws = wb.active

    # ==========================================
    # æº–å‚™æ•¸æ“šå­—å…¸
    # ==========================================
    global_total_grains_by_product = {} 
    global_total_packs_all = 0
    
    data_dict = {}
    for index, row in combined_df.iterrows():
        store = str(row['åº—å']).strip()
        product = str(row['å“å']).strip()
        sales = row['å”®é‡']
        
        if store not in data_dict:
            data_dict[store] = {}
        
        # æ¨¡ç³ŠåŒ¹é…
        matched_key = product
        for key in grains_per_pack_map.keys():
            if key in product:
                matched_key = key
                break
        data_dict[store][matched_key] = data_dict[store].get(matched_key, 0) + sales

    # ==========================================
    # æ­¥é©Ÿ 1: å®šä½èˆ‡æƒææ¬„ä½çµæ§‹ (Wide Scan)
    # ==========================================
    header_row = 3
    store_col_index = 1 # é è¨­ A æ¬„
    
    # æ‰¾ Header Row
    for r in range(1, 10):
        found = False
        for c in range(1, 10):
            val = ws.cell(row=r, column=c).value
            if val and "åº—" in str(val):
                header_row = r
                store_col_index = c
                found = True
                break
        if found: break
    
    # æ‰¾å‡ºæ‰€æœ‰çš„ (å“åæ¬„, å”®é‡æ¬„) é…å°
    # é‚è¼¯ï¼šåªè¦æ¨™é¡Œæ˜¯ "å“å" ä¸”å³é‚Šæ˜¯ "å”®é‡"ï¼Œå°±æ˜¯ä¸€çµ„
    col_pairs = [] # list of tuple (prod_col, sales_col)
    
    for c in range(1, ws.max_column + 1):
        val1 = str(ws.cell(row=header_row, column=c).value).strip()
        val2 = str(ws.cell(row=header_row, column=c+1).value).strip()
        
        if "å“å" in val1 and "å”®é‡" in val2:
            col_pairs.append((c, c+1))

    # ==========================================
    # æ­¥é©Ÿ 2: å¡«å¯«éŠ·å”®æ•¸æ“š (Main Data Filling)
    # ==========================================
    # å¾ Header ä¸‹ä¸€è¡Œé–‹å§‹æƒææ¯ä¸€åˆ—
    for r in range(header_row + 1, ws.max_row + 1):
        cell_store = ws.cell(row=r, column=store_col_index).value
        
        # è·³éç©ºè¡Œæˆ–ç‰¹æ®Šè¡Œ
        if not cell_store: continue
        if "éŠ·å”®" in str(cell_store) or "åˆè¨ˆ" in str(cell_store): continue
        
        store_name = str(cell_store).strip()
        
        # å°é€™ä¸€åˆ—çš„æ¯ä¸€çµ„ (Prod, Sales) é€²è¡Œæª¢æŸ¥èˆ‡å¡«å¯«
        for (prod_col, sales_col) in col_pairs:
            # è®€å– Excel é è¨­çš„å“å
            cell_prod = ws.cell(row=r, column=prod_col).value
            if not cell_prod: continue
            
            prod_name_in_excel = str(cell_prod).strip()
            
            # åœ¨æ•¸æ“šåº«ä¸­å°‹æ‰¾
            if store_name in data_dict:
                sales_val = 0
                # å˜—è©¦åŒ¹é…
                for key_prod in data_dict[store_name]:
                    if key_prod in prod_name_in_excel or prod_name_in_excel in key_prod:
                        sales_val = data_dict[store_name][key_prod]
                        break
                
                # å¦‚æœæœ‰æ•¸æ“šï¼Œå¼·åˆ¶å¯«å…¥ (é€™è§£æ±ºäº† 24 è®Š 100 çš„å•é¡Œ)
                if sales_val > 0:
                    safe_write(ws, r, sales_col, sales_val)

    # ==========================================
    # æ­¥é©Ÿ 3: è™•ç†ã€Œç´…è‰²åŒ…æ•¸ã€èˆ‡ã€Œè—è‰²ç²’æ•¸ã€ (Per-Store Totals)
    # ==========================================
    # æ‰¾å‡ºæ‰€æœ‰ "éŠ·å”®åŒ…æ•¸" çš„è¡Œ
    pack_rows = []
    for r in range(1, ws.max_row + 1):
        val = ws.cell(row=r, column=store_col_index).value
        if val and "éŠ·å”®åŒ…æ•¸" in str(val):
            pack_rows.append(r)

    for r_pack in pack_rows:
        r_grain = -1
        # æ‰¾ä¸‹ä¸€è¡Œçš„ "éŠ·å”®ç²’æ•¸"
        next_cell = ws.cell(row=r_pack + 1, column=store_col_index).value
        if next_cell and "éŠ·å”®ç²’æ•¸" in str(next_cell):
            r_grain = r_pack + 1

        # é‡å°æ¯ä¸€çµ„ (Prod, Sales) é€²è¡Œçµ±è¨ˆ
        for (prod_col, sales_col) in col_pairs:
            # å¾€ä¸Šæ‰¾å“å (æœ€å¤šæ‰¾ 5 æ ¼)
            found_product = None
            for offset in range(1, 6):
                val = ws.cell(row=r_pack - offset, column=prod_col).value
                if val and isinstance(val, str) and len(val) > 1:
                    # æª¢æŸ¥æ˜¯ä¸æ˜¯å·²çŸ¥çš„ç”¢å“
                    for key in grains_per_pack_map.keys():
                        if key in val:
                            found_product = key
                            break
                    if found_product: break
            
            if found_product:
                # 1. å¯«å…¥ç¶ è‰² (ç²’æ•¸è¨­å®š) -> å¯«åœ¨ Product Column
                setting_val = grains_per_pack_map.get(found_product)
                safe_write(ws, r_pack, prod_col, setting_val)
                
                # 2. è¨ˆç®—ç´…è‰² (è©²å€å¡Šç¸½åŒ…æ•¸) -> è®€å– Sales Column
                current_red_sum = 0
                for offset in range(1, 20): # å¾€ä¸Šæƒæ
                    r_scan = r_pack - offset
                    if r_scan <= header_row: break
                    
                    # ç¢ºä¿æ˜¯åŒä¸€å®¶åº—çš„ç¯„åœ (ç°¡å–®åˆ¤æ–·: å·¦é‚Šæœ‰åº—åæˆ–è€…æ˜¯æ•¸æ“šå€)
                    # é€™è£¡ç›´æ¥è®€å–æ•¸å€¼ç´¯åŠ 
                    val = ws.cell(row=r_scan, column=sales_col).value
                    if isinstance(val, (int, float)):
                        current_red_sum += val
                
                # å¯«å…¥ç´…è‰² -> å¯«åœ¨ Sales Column
                safe_write(ws, r_pack, sales_col, current_red_sum)
                
                # å…¨åŸŸç´¯åŠ 
                global_total_packs_all += current_red_sum
                
                # 3. è¨ˆç®—èˆ‡å¯«å…¥è—è‰² (ç¸½ç²’æ•¸) -> å¯«åœ¨ Sales Column
                total_grains = current_red_sum * setting_val
                if r_grain != -1:
                    safe_write(ws, r_grain, sales_col, total_grains)
                
                # å…¨åŸŸç´¯åŠ 
                if found_product not in global_total_grains_by_product:
                    global_total_grains_by_product[found_product] = 0
                global_total_grains_by_product[found_product] += total_grains

    # ==========================================
    # æ­¥é©Ÿ 4: è™•ç†æœ€ä¸‹æ–¹çš„ç¸½çµç®— (Summary Row)
    # ==========================================
    row_summary = -1
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 10):
            val = str(ws.cell(row=r, column=c).value).strip()
            if "ç²’æ•¸ç¸½è¨ˆ" in val:
                row_summary = r
                break
        if row_summary != -1: break

    exclude_list = ["å¤šè", "æ™®é€š"]

    # A. å¡«å¯«ç²’æ•¸ç¸½è¨ˆ
    if row_summary != -1:
        # åªå¡«å¯« Sales Columnï¼Œè·³é Product Column
        for (prod_col, sales_col) in col_pairs:
            # æˆ‘å€‘éœ€è¦çŸ¥é“é€™ä¸€æ¬„å°æ‡‰ä»€éº¼ç”¢å“ï¼Ÿå¾€ä¸Šæ‰¾ header é™„è¿‘çš„æ•¸æ“š
            # ç°¡å–®ä¸€é»ï¼šéæ­· global_total_grains_by_product ä¾†åŒ¹é…
            # æ›´å¥½çš„æ–¹æ³•ï¼šé‡æ–°ç¢ºèªé€™ä¸€æ¬„çš„å“å
            
            # å¾€ä¸Šæ‰¾ header row çš„å“å (é›–ç„¶ header å¯« "å“å"ï¼Œä½†æˆ‘å€‘éœ€è¦çŸ¥é“æ˜¯å“ªå€‹ç”¢å“)
            # æˆ‘å€‘å¯ä»¥ç”¨å‰›å‰›çš„é‚è¼¯ï¼šè©² sales_col å°æ‡‰åˆ°çš„ found_product
            # ç‚ºäº†æ•ˆç‡ï¼Œæˆ‘å€‘é€™è£¡ä¸åšè¤‡é›œå›æº¯ï¼Œè€Œæ˜¯å‡è¨­ column order æ²’è®Š
            # è®“æˆ‘å€‘ç”¨ä¸€å€‹æ›´ç©©çš„æ–¹æ³•ï¼šéæ­·æ‰€æœ‰ sales_colï¼Œå¾€ä¸Šæ‰¾ç”¢å“å
            
            target_product = None
            # æ‰¾é€™ä¸€æ¬„ä¸Šé¢çš„ç´…è‰²æ ¼å­é™„è¿‘çš„ç”¢å“å
            # æ‰¾ç¬¬ä¸€å€‹ pack_row
            if pack_rows:
                first_pack_row = pack_rows[0]
                # å¾€ä¸Šæ‰¾
                for offset in range(1, 6):
                    val = ws.cell(row=first_pack_row - offset, column=prod_col).value
                    if val:
                         for key in grains_per_pack_map.keys():
                            if key in str(val):
                                target_product = key
                                break
                    if target_product: break
            
            if target_product and target_product not in exclude_list:
                val = global_total_grains_by_product.get(target_product, 0)
                safe_write(ws, row_summary, sales_col, val)
            else:
                # ä¸å¡«å¯«ï¼Œæˆ–å¡«ç©º
                safe_write(ws, row_summary, sales_col, "")

    # B. å¡«å¯«ç¸½ç²’æ•¸èˆ‡ç¸½åŒ…æ•¸ (Smart Jump)
    grand_total_grains = sum(global_total_grains_by_product.values())
    
    for r in range(ws.max_row, 1, -1):
        for c in range(1, 20): 
            current_cell = ws.cell(row=r, column=c)
            val = str(current_cell.value).strip()
            
            is_total_grains = "ç¸½ç²’æ•¸" in val
            is_total_packs = "ç¸½åŒ…æ•¸" in val
            
            if is_total_grains or is_total_packs:
                target_col = c + 1
                # æª¢æŸ¥åˆä½µå„²å­˜æ ¼è·³èº
                for rng in ws.merged_cells.ranges:
                    if current_cell.coordinate in rng:
                        target_col = rng.max_col + 1
                        break
                
                if is_total_grains:
                    safe_write(ws, r, target_col, grand_total_grains)
                elif is_total_packs:
                    safe_write(ws, r, target_col, global_total_packs_all)

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    return output

# --- 3. Streamlit ä»‹é¢ ---
st.set_page_config(page_title="æª³æ¦”å ±è¡¨ç”Ÿæˆå™¨ (v13 å¯¬ç‰ˆæƒæç‰ˆ)", layout="wide")
st.title("ğŸ­ æª³æ¦”éŠ·å”®å ±è¡¨è‡ªå‹•ç”Ÿæˆ")

DEFAULT_TEMPLATE = "æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx"

col1, col2 = st.columns([1, 2])
with col1:
    st.markdown("### 1. æ¨¡æ¿è¨­å®š")
    if os.path.exists(DEFAULT_TEMPLATE):
        st.success(f"âœ… ä½¿ç”¨é è¨­æ¨¡æ¿ï¼š{DEFAULT_TEMPLATE}")
        use_default = st.checkbox("ä½¿ç”¨é è¨­æ¨¡æ¿", value=True)
        template_file = DEFAULT_TEMPLATE if use_default else None
        if not use_default:
            template_file = st.file_uploader("ä¸Šå‚³æ–°æ¨¡æ¿", type=["xlsx"])
    else:
        st.warning("âš ï¸ è«‹ä¸Šå‚³ Excel æ¨¡æ¿")
        template_file = st.file_uploader("ä¸Šå‚³æ¨¡æ¿", type=["xlsx"])

with col2:
    st.markdown("### 2. åŸå§‹æ•¸æ“š")
    source_files = st.file_uploader("ä¸Šå‚³æ‰€æœ‰æ•¸æ“šæª”æ¡ˆ (æ”¯æ´ xls, xlsx, csv)", type=["csv", "xls", "xlsx"], accept_multiple_files=True)

default_grains = {
    "ç‰¹å¹¼": 8, "å¹¼å¤§å£": 8, "å¤šç²’": 12, "å¤šå¤§å£": 12,
    "å¹¼è": 10, "é›™å­æ˜Ÿ": 10, "å¤šè": 10, "æ™®é€š": 10
}

st.markdown("### 3. è¨­å®šæ¯åŒ…ç²’æ•¸")
cols = st.columns(4)
user_grains_setting = {}

for i, (product, default_val) in enumerate(default_grains.items()):
    with cols[i % 4]:
        val = st.number_input(f"{product}", value=default_val, step=1)
        user_grains_setting[product] = val

if st.button("ğŸš€ ç”Ÿæˆå ±è¡¨", type="primary"):
    current_template = template_file if template_file else (DEFAULT_TEMPLATE if os.path.exists(DEFAULT_TEMPLATE) else None)

    if not current_template:
        st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æª”æ¡ˆï¼")
    elif not source_files:
        st.error("è«‹ä¸Šå‚³åŸå§‹æ•¸æ“šæª”æ¡ˆã€‚")
    else:
        with st.spinner("æ­£åœ¨è§£æèˆ‡è¨ˆç®—..."):
            all_data = []
            error_logs = []
            
            for f in source_files:
                df, msg = load_and_fix_smart(f)
                if df is not None:
                    df['ä¾†æºæª”æ¡ˆ'] = f.name 
                    all_data.append(df)
                else:
                    error_logs.append(f"âŒ {f.name}: {msg}")
            
            if error_logs:
                with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè®€å–å¤±æ•—"):
                    for log in error_logs:
                        st.code(log)
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                st.info(f"âœ… æˆåŠŸè®€å– {len(combined_df)} ç­†è³‡æ–™ã€‚")
                
                with st.expander("ğŸ” é»æ“ŠæŸ¥çœ‹æ•¸æ“šè©³æƒ…"):
                    st.dataframe(combined_df)

                try:
                    result_excel = fill_excel_template(current_template, combined_df, user_grains_setting)
                    st.success("å ±è¡¨ç”ŸæˆæˆåŠŸï¼å·²ä¿®æ­£å¯¬è¡¨æ ¼è®€å–å•é¡Œã€‚")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å ±è¡¨",
                        data=result_excel,
                        file_name="å·²å¡«å¯«_æª³æ¦”éŠ·å”®çµ±è¨ˆ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¡«å¯« Excel æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æˆåŠŸè®€å–ã€‚")
